{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bce866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "All Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Eslam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "print(\"-\"*100)\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87aaf550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07cfc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='Clinical Scenario: Dynamic knee valgus (DKV) is a mechanical alteration in the knee that leads to increased risk of injury. Weakness of hip musculature in hip abduction (HABD), extension (HEXT), and external rotation (HER) may contribute to increased DKV in single-leg landing tasks. Focused Clinical Question: Is decreased hip strength associated with an increase in DKV during a single-leg landing task in collegiate female athletes? Summary of Key Findings: Three studies were included: One randomized control trial (RCT), one cohort study, and one case-control. All three studies found that decreases in HABD and HER strength contributed to increased DKV during single-leg landing tasks. One study also found that the hip extensors contribute to controlling hip adduction, a common factor in many mechanisms of injuries. These three studies recommended strengthening HABD, HEXT, and HER to decrease DKV and reduce the risk of injury at the knee. Clinical Bottom Line: Weak HABD, HEXT, and HER contribute to increased DKV in college female athletes, but strengthening HABD, HEXT, and HER can lead to decreases in DKV and, overall, reduce the risk of injury at the knee. Strength of Recommendation: These articles were graded with a level of evidence of III or higher, giving a grade of B strength of recommendation that weak HABD, HEXT, and HER are associated with increased DKV in collegiate female athletes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb7e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=re.sub('[,\\.!?]', '', sentence.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e59145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clinical scenario: dynamic knee valgus (dkv) is a mechanical alteration in the knee that leads to increased risk of injury weakness of hip musculature in hip abduction (habd) extension (hext) and external rotation (her) may contribute to increased dkv in single-leg landing tasks focused clinical question: is decreased hip strength associated with an increase in dkv during a single-leg landing task in collegiate female athletes summary of key findings: three studies were included: one randomized control trial (rct) one cohort study and one case-control all three studies found that decreases in habd and her strength contributed to increased dkv during single-leg landing tasks one study also found that the hip extensors contribute to controlling hip adduction a common factor in many mechanisms of injuries these three studies recommended strengthening habd hext and her to decrease dkv and reduce the risk of injury at the knee clinical bottom line: weak habd hext and her contribute to increased dkv in college female athletes but strengthening habd hext and her can lead to decreases in dkv and overall reduce the risk of injury at the knee strength of recommendation: these articles were graded with a level of evidence of iii or higher giving a grade of b strength of recommendation that weak habd hext and her are associated with increased dkv in collegiate female athletes'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b424e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical',\n",
       " 'scenario',\n",
       " 'dynamic',\n",
       " 'knee',\n",
       " 'valgus',\n",
       " 'dkv',\n",
       " 'is',\n",
       " 'mechanical',\n",
       " 'alteration',\n",
       " 'in',\n",
       " 'the',\n",
       " 'knee',\n",
       " 'that',\n",
       " 'leads',\n",
       " 'to',\n",
       " 'increased',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'injury',\n",
       " 'weakness',\n",
       " 'of',\n",
       " 'hip',\n",
       " 'musculature',\n",
       " 'in',\n",
       " 'hip',\n",
       " 'abduction',\n",
       " 'habd',\n",
       " 'extension',\n",
       " 'hext',\n",
       " 'and',\n",
       " 'external',\n",
       " 'rotation',\n",
       " 'her',\n",
       " 'may',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'increased',\n",
       " 'dkv',\n",
       " 'in',\n",
       " 'single',\n",
       " 'leg',\n",
       " 'landing',\n",
       " 'tasks',\n",
       " 'focused',\n",
       " 'clinical',\n",
       " 'question',\n",
       " 'is',\n",
       " 'decreased',\n",
       " 'hip',\n",
       " 'strength',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'an',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'dkv',\n",
       " 'during',\n",
       " 'single',\n",
       " 'leg',\n",
       " 'landing',\n",
       " 'task',\n",
       " 'in',\n",
       " 'collegiate',\n",
       " 'female',\n",
       " 'athletes',\n",
       " 'summary',\n",
       " 'of',\n",
       " 'key',\n",
       " 'findings',\n",
       " 'three',\n",
       " 'studies',\n",
       " 'were',\n",
       " 'included',\n",
       " 'one',\n",
       " 'randomized',\n",
       " 'control',\n",
       " 'trial',\n",
       " 'rct',\n",
       " 'one',\n",
       " 'cohort',\n",
       " 'study',\n",
       " 'and',\n",
       " 'one',\n",
       " 'case',\n",
       " 'control',\n",
       " 'all',\n",
       " 'three',\n",
       " 'studies',\n",
       " 'found',\n",
       " 'that',\n",
       " 'decreases',\n",
       " 'in',\n",
       " 'habd',\n",
       " 'and',\n",
       " 'her',\n",
       " 'strength',\n",
       " 'contributed',\n",
       " 'to',\n",
       " 'increased',\n",
       " 'dkv',\n",
       " 'during',\n",
       " 'single',\n",
       " 'leg',\n",
       " 'landing',\n",
       " 'tasks',\n",
       " 'one',\n",
       " 'study',\n",
       " 'also',\n",
       " 'found',\n",
       " 'that',\n",
       " 'the',\n",
       " 'hip',\n",
       " 'extensors',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'controlling',\n",
       " 'hip',\n",
       " 'adduction',\n",
       " 'common',\n",
       " 'factor',\n",
       " 'in',\n",
       " 'many',\n",
       " 'mechanisms',\n",
       " 'of',\n",
       " 'injuries',\n",
       " 'these',\n",
       " 'three',\n",
       " 'studies',\n",
       " 'recommended',\n",
       " 'strengthening',\n",
       " 'habd',\n",
       " 'hext',\n",
       " 'and',\n",
       " 'her',\n",
       " 'to',\n",
       " 'decrease',\n",
       " 'dkv',\n",
       " 'and',\n",
       " 'reduce',\n",
       " 'the',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'injury',\n",
       " 'at',\n",
       " 'the',\n",
       " 'knee',\n",
       " 'clinical',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'weak',\n",
       " 'habd',\n",
       " 'hext',\n",
       " 'and',\n",
       " 'her',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'increased',\n",
       " 'dkv',\n",
       " 'in',\n",
       " 'college',\n",
       " 'female',\n",
       " 'athletes',\n",
       " 'but',\n",
       " 'strengthening',\n",
       " 'habd',\n",
       " 'hext',\n",
       " 'and',\n",
       " 'her',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'decreases',\n",
       " 'in',\n",
       " 'dkv',\n",
       " 'and',\n",
       " 'overall',\n",
       " 'reduce',\n",
       " 'the',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'injury',\n",
       " 'at',\n",
       " 'the',\n",
       " 'knee',\n",
       " 'strength',\n",
       " 'of',\n",
       " 'recommendation',\n",
       " 'these',\n",
       " 'articles',\n",
       " 'were',\n",
       " 'graded',\n",
       " 'with',\n",
       " 'level',\n",
       " 'of',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'iii',\n",
       " 'or',\n",
       " 'higher',\n",
       " 'giving',\n",
       " 'grade',\n",
       " 'of',\n",
       " 'strength',\n",
       " 'of',\n",
       " 'recommendation',\n",
       " 'that',\n",
       " 'weak',\n",
       " 'habd',\n",
       " 'hext',\n",
       " 'and',\n",
       " 'her',\n",
       " 'are',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'increased',\n",
       " 'dkv',\n",
       " 'in',\n",
       " 'collegiate',\n",
       " 'female',\n",
       " 'athletes']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words=gensim.utils.simple_preprocess(sentence, deacc=True)\n",
    "data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b3a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Eslam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out=[token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "206bbdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['athlete']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf23c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "    text=nlp(text)\n",
    "    if text.pos_ in allowed_postags:\n",
    "        return text.lemma_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00f9d7c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5d8a24f3dae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlemmatize_stemming\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"eslam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-cd83c75004b8>\u001b[0m in \u001b[0;36mlemmatize_stemming\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mallowed_postags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NOUN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VERB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADV'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "lemmatize_stemming(\"eslam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out=[token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c10df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    doc = nlp(text) \n",
    "    if token.pos_ in allowed_postags:  \n",
    "        return token.lemma_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f2ef166",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-fe618a047fbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlemmatization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ran\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-6033f42f9c07>\u001b[0m in \u001b[0;36mlemmatization\u001b[1;34m(token, allowed_postags)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"https://spacy.io/api/annotation\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "lemmatization(\"ran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "006ffb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=re.sub('[,\\.!?]', '', sentence.lower())\n",
    "ls=[]\n",
    "for token in gensim.utils.simple_preprocess(sentence,deacc=True):\n",
    "    \n",
    "    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 4:\n",
    "        ls.append(token)\n",
    "doc=nlp(\" \".join(ls)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89c33cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clinical scenario dynamic valgus mechanical alteration leads increased injury weakness musculature abduction extension external rotation contribute increased single landing tasks focused clinical question decreased strength associated increase single landing collegiate female athletes summary findings studies included randomized control trial cohort study control studies decreases strength contributed increased single landing tasks study extensors contribute controlling adduction common factor mechanisms injuries studies recommended strengthening decrease reduce injury clinical contribute increased college female athletes strengthening decreases overall reduce injury strength recommendation articles graded level evidence higher giving grade strength recommendation associated increased collegiate female athletes"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a821465",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "sen=[]\n",
    "for token in doc :\n",
    "    if token.pos_ in allowed_postags:  \n",
    "        sen.append(token.lemma_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dee468ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical',\n",
       " 'scenario',\n",
       " 'dynamic',\n",
       " 'mechanical',\n",
       " 'alteration',\n",
       " 'lead',\n",
       " 'increase',\n",
       " 'injury',\n",
       " 'weakness',\n",
       " 'musculature',\n",
       " 'abduction',\n",
       " 'extension',\n",
       " 'external',\n",
       " 'rotation',\n",
       " 'contribute',\n",
       " 'increase',\n",
       " 'single',\n",
       " 'landing',\n",
       " 'task',\n",
       " 'focus',\n",
       " 'clinical',\n",
       " 'question',\n",
       " 'decrease',\n",
       " 'strength',\n",
       " 'associate',\n",
       " 'increase',\n",
       " 'single',\n",
       " 'landing',\n",
       " 'collegiate',\n",
       " 'female',\n",
       " 'athlete',\n",
       " 'summary',\n",
       " 'finding',\n",
       " 'study',\n",
       " 'include',\n",
       " 'randomize',\n",
       " 'control',\n",
       " 'trial',\n",
       " 'cohort',\n",
       " 'study',\n",
       " 'control',\n",
       " 'study',\n",
       " 'decrease',\n",
       " 'strength',\n",
       " 'contribute',\n",
       " 'increase',\n",
       " 'single',\n",
       " 'landing',\n",
       " 'task',\n",
       " 'study',\n",
       " 'extensor',\n",
       " 'contribute',\n",
       " 'control',\n",
       " 'adduction',\n",
       " 'common',\n",
       " 'factor',\n",
       " 'mechanism',\n",
       " 'injury',\n",
       " 'study',\n",
       " 'recommend',\n",
       " 'strengthen',\n",
       " 'decrease',\n",
       " 'reduce',\n",
       " 'injury',\n",
       " 'clinical',\n",
       " 'contribute',\n",
       " 'increase',\n",
       " 'college',\n",
       " 'female',\n",
       " 'athlete',\n",
       " 'strengthen',\n",
       " 'decrease',\n",
       " 'overall',\n",
       " 'reduce',\n",
       " 'injury',\n",
       " 'strength',\n",
       " 'recommendation',\n",
       " 'article',\n",
       " 'grade',\n",
       " 'level',\n",
       " 'evidence',\n",
       " 'higher',\n",
       " 'give',\n",
       " 'grade',\n",
       " 'strength',\n",
       " 'recommendation',\n",
       " 'associate',\n",
       " 'increase',\n",
       " 'collegiate',\n",
       " 'female',\n",
       " 'athlete']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31e3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
